# Lambda_Feedback_Gao

This is the repository of Gao Zhuangfei's Final Year Project.

## ğŸ“¦ Setup
1. Install all dependencies from `requirements.txt`.

## ğŸ“ Repository Overview

- `functions/`: All executable modules including Python scripts, PostgreSQL scripts, and LoRA training components.
- `test_results/`: Outputs from evaluation runs on various large language models (LLMs), including both baseline and LoRA-augmented tests.
- `non_functions/`: Supplementary resources such as notes, version control records, and environment setup scripts.
- `shortTextAnswer/`: Forked branch from the Lambda Feedback repo â€” refer to its internal `README` for app-specific instructions.
- `docs/`: Documentation files related to the project.

## ğŸ”— External Resources

- HuggingFace datasets and models:  
  ğŸ‘‰ [https://huggingface.co/Bigbigboss02](https://huggingface.co/Bigbigboss02)

---

## ğŸ“‚ Project Folder Structure
<pre lang="markdown">
```
Lambda_Feedback_Gao/
â”œâ”€â”€ docs/
â”œâ”€â”€ shortTextAnswer/                  # Forked Lambda Feedback branch, see internal README
â”‚   â”œâ”€â”€ app/
â”‚   â””â”€â”€ .github/
â”œâ”€â”€ non_functions/                    # Non-experiment resources
â”‚   â”œâ”€â”€ version_control/
â”‚   â”œâ”€â”€ cuda_env_test/
â”‚   â””â”€â”€ notes_and_literatures/
â”œâ”€â”€ functions/                        # Experiment-related code and modules
â”‚   â”œâ”€â”€ postgreSQL_script/           # Low value â€” initial SQL scripts
â”‚   â”‚   â””â”€â”€ tests/
â”‚   â”œâ”€â”€ python_script/               # Moderate value â€” core Python scripts
â”‚   â”‚   â”œâ”€â”€ tools/
â”‚   â”‚   â”œâ”€â”€ Archive/                 # Low value â€” archived versions
â”‚   â”‚   â”œâ”€â”€ tests/                   # Moderate value â€” test functions
â”‚   â”‚   â”œâ”€â”€ Evaluation_functions/    # Low value â€” early LLM evals
â”‚   â”‚   â”œâ”€â”€ structured_prompts/      # Low value â€” prompt logic separation
â”‚   â”‚   â”‚   â”œâ”€â”€ LongChain/
â”‚   â”‚   â”‚   â””â”€â”€ confusion_matrix/
â”‚   â”‚   â””â”€â”€ Severless_API_calls/     # Moderate value â€” GPT-4o-mini endpoint calls
â”‚   â”œâ”€â”€ LoRa/                        # High value â€” training/testing LoRA modules
â”‚   â”‚   â”œâ”€â”€ calling_functions/       # High value â€” LoRA model interface
â”‚   â”‚   â”œâ”€â”€ adaptors/                # High/Moderate value â€” trained LoRA weights
â”‚   â”‚   â”‚   â”œâ”€â”€ tuned_Llama321B_adaptors/
â”‚   â”‚   â”‚   â”œâ”€â”€ tuned_BeRT_adaptors/
â”‚   â”‚   â”‚   â”œâ”€â”€ tuned_Llama321B_balanced_dataset/
â”‚   â”‚   â”‚   â””â”€â”€ selected_Llama321B_adaptors/
â”‚   â”‚   â”œâ”€â”€ testing_functions/       # Moderate value
â”‚   â”‚   â””â”€â”€ data/                    # High value â€” training/testing sets
â”‚   â”‚       â””â”€â”€ waste_data/          # Low value
â”‚   â””â”€â”€ google_colab_script/         # High value â€” LoRA training notebook
â”œâ”€â”€ test_results/                    # High value â€” model test results, includes everything in Paper Results
â”‚   â”œâ”€â”€ Smaller_LLM_tests/
â”‚   â”‚   â”œâ”€â”€ LoRa_controlled_variable_tests/
â”‚   â”‚   â”œâ”€â”€ Base_controlled_variable_tests/
â”‚   â”‚   â”œâ”€â”€ Llama3_1B_initial_test/
â”‚   â”‚   â””â”€â”€ initial_finetuned_model_test/
â”‚   â”œâ”€â”€ Larger_LLM_tests/
â”‚   â”‚   â”œâ”€â”€ Base_gpt4o_llama3_crossplatform/
â”‚   â”‚   â”œâ”€â”€ initial_base_model_tests/
â”‚   â”‚   â”‚   â”œâ”€â”€ week15_experiments/
â”‚   â”‚   â”‚   â””â”€â”€ week16_experiments/
â”‚   â”‚   â””â”€â”€ Cross_Platform_Comparison/
â”‚   â”‚       â”œâ”€â”€ Llama3_3B_test/
â”‚   â”‚       â”œâ”€â”€ GPT-4o_mini_8B_test/
â”‚   â”‚       â””â”€â”€ Llama3_1B_test/
```
</pre>
